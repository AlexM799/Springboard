{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 72831 entries, 2018-01-01 to 2018-01-01\n",
      "Data columns (total 51 columns):\n",
      "Region of residence                                                     72831 non-null category\n",
      "Type of living quarters                                                 72831 non-null category\n",
      "Sex                                                                     72831 non-null category\n",
      "Legal marital status                                                    72831 non-null category\n",
      "Main Racial Background                                                  72831 non-null category\n",
      "Hispanic ethnicity                                                      72831 non-null category\n",
      "Number of years spent in the U.S.                                       72831 non-null int64\n",
      "Above or below poverty threshold                                        72831 non-null category\n",
      "Total combined family income                                            72831 non-null category\n",
      "Person's total earnings, previous calendar year                         72831 non-null category\n",
      "Has usual place for medical care                                        72831 non-null category\n",
      "Kind of usual place for medical care                                    72831 non-null category\n",
      "Medical care delayed due to cost, past 12 months                        72831 non-null category\n",
      "Changed usual place for health care for insurance reasons               72831 non-null category\n",
      "Needed but couldn't afford medical care, past 12 months                 72831 non-null category\n",
      "Needed but couldn't afford dental care, past 12 months                  72831 non-null category\n",
      "Needed but couldn't afford prescription medicines, past 12 months       72831 non-null category\n",
      "Needed but couldn't afford mental health care, past 12 months           72831 non-null category\n",
      "Ever told had ADHD/ADD                                                  72831 non-null category\n",
      "Ever told had angina pectoris                                           72831 non-null category\n",
      "Ever told had asthma                                                    72831 non-null category\n",
      "Ever told had cancer                                                    72831 non-null category\n",
      "Ever had chickenpox                                                     72831 non-null category\n",
      "Ever told had diabetes                                                  72831 non-null category\n",
      "Ever told had emphysema                                                 72831 non-null category\n",
      "Ever told had heart attack                                              72831 non-null category\n",
      "Ever told had heart condition/disease                                   72831 non-null category\n",
      "Ever told had hypertension                                              72831 non-null category\n",
      "Ever told had a learning disability                                     72831 non-null category\n",
      "Ever told had a stroke                                                  72831 non-null category\n",
      "Ever told had ulcer                                                     72831 non-null category\n",
      "Has trouble seeing                                                      72831 non-null category\n",
      "Days had 5+ drinks, past year                                           72831 non-null category\n",
      "Ever smoked 100 cigarettes in life                                      72831 non-null category\n",
      "Age first smoked fairly regularly                                       72831 non-null int64\n",
      "Number cigarettes per day (current smokers)                             72831 non-null int64\n",
      "Cigarette smoking                                                       72831 non-null category\n",
      "Frequency of moderate activity 10+ minutes: Times per week              72831 non-null int64\n",
      "Frequency of vigorous activity 10+ minutes: Times per week              72831 non-null int64\n",
      "Frequency of strengthening activity: Times per week                     72831 non-null int64\n",
      "Has any activity limitation                                             72831 non-null category\n",
      "Number of family members with unmet need for care, past 12 months       72831 non-null int64\n",
      "Any family member limited by difficulty remembering                     72831 non-null category\n",
      "Number of family members in poor health                                 72831 non-null int64\n",
      "Any family members have difficulty walking without special equipment    72831 non-null category\n",
      "Any family member with work limitation due to health problem            72831 non-null category\n",
      "Overall functional limitation recode by condition status                72831 non-null category\n",
      "Quality of hearing without hearing aid                                  72831 non-null category\n",
      "Felt everything an effort, past 30 days                                 72831 non-null category\n",
      "How often felt hopeless, past 30 days                                   72831 non-null category\n",
      "How often felt worthless, past 30 days                                  72831 non-null category\n",
      "dtypes: category(43), int64(8)\n",
      "memory usage: 8.0 MB\n",
      "None\n",
      "Done with analysis, creating Pandas Profiling Report\n",
      "Done!\n",
      "time taken:  0:02:12.530817\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pandas_profiling\n",
    "\n",
    "def col_unknown_response_dict():\n",
    "    \"\"\" Return a dictionary of column names as keys and values as a list of unknown/refuse codes to question\n",
    "    \"\"\"\n",
    "    urd = {}\n",
    "    urd['REGION'] = [9]\n",
    "    urd['LIVINGQTR'] = [98]\n",
    "    urd['MARSTAT'] = [0, 99]\n",
    "    urd['RACEA'] = [900, 970, 980]\n",
    "    urd['HISPETH'] = [93, 99]\n",
    "    urd['YRSINUS'] = [0, 7, 8, 9]\n",
    "    urd['NOWAF'] = [0, 7, 8, 9]\n",
    "    urd['POORYN'] = [9]\n",
    "    urd['INCFAM97ON2'] = [97, 98, 99]\n",
    "    urd['EARNINGS'] = [0, 97, 98, 99]\n",
    "    urd['USUALPL'] = [0, 7, 8, 9]\n",
    "    urd['TYPPLSICK'] = [0, 97, 98, 99]\n",
    "    urd['ALC5UPYR'] = [996, 997, 998, 999]\n",
    "    urd['SMOKAGEREG'] = [0, 97, 98, 99]\n",
    "    urd['CIGSDAY'] = [96, 97, 98, 99]\n",
    "    urd['SMOKESTATUS2'] = [0, 90]\n",
    "    urd['LANY'] = [22]\n",
    "    urd['CLIMALC'] = [0, 7, 8, 9]\n",
    "    urd['HEARING'] = [0, 97, 98, 99]\n",
    "    urd['AEFFORT'] = [6, 7, 8, 9]\n",
    "    urd['AHOPELESS'] = [6, 7, 8, 9]\n",
    "    urd['AWORTHLESS'] = [6, 7, 8, 9]\n",
    "\n",
    "    return urd\n",
    "\n",
    "\n",
    "def write_results_header(working_df, working_filename, results_filename):\n",
    "    \"\"\"save summary information to results file\n",
    "    \"\"\"\n",
    "    cols_with_nulls = df.columns[df.isnull().any()]\n",
    "    with open(results_filename, 'w+') as f:   \n",
    "        f.write('Review of file ' + working_filename + '\\n\\n')\n",
    "        f.write('Rows: ' + str(len(working_df.index)) + '\\n')\n",
    "        f.write('Columns with null data: \\n')\n",
    "        if len(cols_with_nulls) == 0:\n",
    "            f.write('None\\n')\n",
    "        else:\n",
    "            for col in cols_with_nulls:\n",
    "                f.write(col + '\\n')\n",
    "        \n",
    "\n",
    "def count_valid_flag_data(working_df, flag_col_filename, results_filename):\n",
    "    \"\"\"create counts of pos/neg responses for flag (yes/no) cols\n",
    "       append counts to results file\n",
    "       return list of flag col names\n",
    "    \"\"\"\n",
    "    flag_cols = pd.read_csv(flag_col_filename)\n",
    "    results_dict = {}\n",
    "\n",
    "    for col in flag_cols:\n",
    "        print('checking flag col ', col)\n",
    "        results_entry = {}\n",
    "\n",
    "        values = df[col].value_counts().keys().tolist()\n",
    "        counts = df[col].value_counts().tolist()\n",
    "        \n",
    "        print('values: ', values)\n",
    "        print('counts: ', counts)\n",
    "\n",
    "        yes_index = values.index(2)\n",
    "        no_index = values.index(1)\n",
    "        results_entry['positive'] = counts[yes_index]\n",
    "        results_entry['negative'] = counts[no_index]\n",
    "        results_entry['percent_positive'] = round(counts[yes_index] / sum(counts), 2)\n",
    "\n",
    "        results_dict[col] = results_entry\n",
    "        \n",
    "    #sort the results in order of most positives to least positives\n",
    "    priority_list = sorted(results_dict, key=lambda x: (results_dict[x]['positive']), reverse=True)\n",
    "\n",
    "    with open(results_filename, 'a') as f:   \n",
    "        f.write('\\nReview of flag data\\n')\n",
    "        f.write('feature, positive_response, negative_response, percent_pos\\n')\n",
    "        for item in priority_list:\n",
    "            f_str = item + ', ' \n",
    "            f_str += str(results_dict[item]['positive']) + ', '\n",
    "            f_str += str(results_dict[item]['negative']) + ', '\n",
    "            f_str += str(results_dict[item]['percent_positive']) + '\\n'\n",
    "            f.write(f_str)\n",
    "\n",
    "    return flag_cols\n",
    "            \n",
    "\n",
    "def count_valid_category_data(working_df, results_filename):\n",
    "    \"\"\"create counts of unknown/refused/not-used responses for cols with category data\n",
    "       append counts to results file\n",
    "    \"\"\"\n",
    "    results_dict = {}\n",
    "    missing_categories = col_unknown_response_dict()\n",
    "    total_responses = len(working_df.index)\n",
    "    \n",
    "    for col in working_df.columns:\n",
    "        results_entry = {}\n",
    "        total_missing = 0\n",
    "        total_responses = 0\n",
    "        \n",
    "        #get the codes for missing values for the column\n",
    "        codes_for_missing = missing_categories.get(col, \"\") \n",
    "        response_codes = working_df[col].value_counts().keys().tolist()\n",
    "\n",
    "        #if the column has missing codes and if any respones match those codes, create the counts\n",
    "        if codes_for_missing != \"\" and set(codes_for_missing).intersection(response_codes): \n",
    "            response_code_counts = working_df[col].value_counts().tolist()\n",
    "            total_responses = sum(response_code_counts)\n",
    "            for code in response_codes:\n",
    "                if code in missing_categories[col]:\n",
    "                    code_index = response_codes.index(code)\n",
    "                    total_missing += response_code_counts[code_index]\n",
    "        \n",
    "            results_entry['valid'] = total_responses - total_missing\n",
    "            results_entry['missing'] = total_missing\n",
    "            results_entry['percent_valid'] = round(results_entry['valid'] / total_responses, 2)\n",
    "\n",
    "            results_dict[col] = results_entry\n",
    "\n",
    "    \n",
    "    #sort the results in order of most valid responses to least valid responses\n",
    "    priority_list = sorted(results_dict, key=lambda x: (results_dict[x]['valid']), reverse=True)\n",
    "    \n",
    "    with open(results_filename, 'a') as f:   \n",
    "        f.write('\\nReview of category data\\n')\n",
    "        f.write('feature, valid_response, missing_response, percent_valid\\n')\n",
    "        for item in priority_list:\n",
    "            f_str = item + ', ' \n",
    "            f_str += str(results_dict[item]['valid']) + ', '\n",
    "            f_str += str(results_dict[item]['missing']) + ', '\n",
    "            f_str += str(results_dict[item]['percent_valid']) + '\\n'\n",
    "            f.write(f_str)\n",
    " \n",
    "    \n",
    "\n",
    "def update_columns(working_df, col_info_filename):\n",
    "    \"\"\" update column names to readable versions, update column types\n",
    "    \"\"\"\n",
    "    info_dict = pd.read_csv(col_info_filename, index_col=0, squeeze=True, header=None).to_dict()\n",
    "    \n",
    "    #set numerical columns\n",
    "    working_df['CIGSDAY'] = pd.to_numeric(working_df['CIGSDAY'])\n",
    "    working_df['SMOKAGEREG'] = pd.to_numeric(working_df['SMOKAGEREG'])\n",
    "    working_df['FHSTATPR'] = pd.to_numeric(working_df['FHSTATPR'])\n",
    "    working_df['MOD10FWK'] = pd.to_numeric(working_df['MOD10FWK'])\n",
    "    working_df['VIG10FWK'] = pd.to_numeric(working_df['VIG10FWK'])\n",
    "    working_df['STRONGFWK'] = pd.to_numeric(working_df['STRONGFWK'])\n",
    "    working_df['YRSINUS'] = pd.to_numeric(working_df['YRSINUS'])\n",
    "    working_df['FNMEDCT'] = pd.to_numeric(working_df['FNMEDCT'])\n",
    "\n",
    "    return working_df.rename(columns=info_dict)\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__': \n",
    "    t0 = datetime.now()\n",
    "    print(\"working!\")\n",
    "\n",
    "    working_file_path = '/Users/alexia/Documents/Springboard/Capstone1/Cap1testing/'\n",
    "    working_file = working_file_path + 'nhis_00009.csv'\n",
    "    flag_col_file = working_file_path + 'nhis_flag_cols.csv'\n",
    "    col_info_file = working_file_path + 'Extract9ColMapping.csv'\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    results_file = working_file_path + 'results' + timestamp + '.csv'\n",
    "\n",
    "    df = pd.read_csv(working_file, parse_dates = True, index_col = 'YEAR', dtype = 'category')\n",
    "    \n",
    "    write_results_header(df, working_file, results_file)\n",
    "    \n",
    "    df = update_columns(df, col_info_file)\n",
    "    print(df.info())\n",
    "    \n",
    "    #cols_analyzed = count_valid_flag_data(df, flag_col_file, results_file)\n",
    "    \n",
    "    ##remove flag columns, get counts on the rest\n",
    "    #df_rest = df.drop(cols_analyzed, axis=1)\n",
    "    #count_valid_category_data(df_rest, results_file)\n",
    "    \n",
    "    print(\"Done with analysis, creating Pandas Profiling Report\")\n",
    "    profile = df.profile_report(title='Pandas Profiling Report')\n",
    "    profile.to_file(output_file= working_file_path + timestamp + \"output.html\")\n",
    "\n",
    "\n",
    "    print(\"Done!\")\n",
    "    total = datetime.now() - t0\n",
    "    print(\"time taken: \", total)\n",
    "    with open(results_file, 'a') as f:   \n",
    "        f.write('\\nReview time = ' + str(total))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
